{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In the above line of code, Libraries of python is imported so that we have easily process our data, visualized and manipulate it.\n",
    "\n",
    "Numpy is the core library for the scientific computing in python. It provides high-performance multidimensional array object and tools for working with arrays.\n",
    "\n",
    "Matplotlib is the data visualization library which helps us to cleary understand the data. It helps us to plot the data in the graphical structure.\n",
    "\n",
    "Pandas is the python datascience related library which is used for data analysis, manipulation data, create the necessary data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = pd.read_csv('nba_2017_att_val_elo_with_cluster.csv',converters={\"TEAM\":str,\"CONF\":str})\n",
    "Data.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In the above shell, Data is read from the pandas and store it in the dataset variable. .read_csv() is the builtin method to read the csv format data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(    GMS   TOTAL    AVG    PCT  VALUE_MILLIONS   ELO  CONF  cluster\n",
       " 0    41  888882  21680  103.6            2500  1519  East        1\n",
       " 1    41  811366  19789  103.1            1450  1420  West        1\n",
       " 2    41  721928  17608  100.6            1075  1393  West        0\n",
       " 3    41  805400  19643  100.2            1350  1569  East        1\n",
       " 4    41  813050  19830  100.2            1125  1600  East        1\n",
       " 5    41  782609  19088  100.1            2000  1636  West        1\n",
       " 6    41  843042  20562  100.0            1200  1545  East        1\n",
       " 7    41  803436  19596  100.0            2600  1770  West        1\n",
       " 8    41  746323  18203  100.0            1025  1543  West        0\n",
       " 9    41  810741  19774   99.8            3300  1374  East        1\n",
       " 10   41  760690  18553   99.6            2200  1587  East        1\n",
       " 11   41  776917  18949   99.4            3000  1367  West        1\n",
       " 12   41  792029  19317   99.4            1050  1563  West        1\n",
       " 13   41  755347  18423   99.2            1175  1661  West        0\n",
       " 14   41  806605  19673   98.8             910  1617  West        1\n",
       " 15   41  727875  17753   94.2             920  1352  East        0\n",
       " 16   41  663099  16173   94.1             750  1482  West        2\n",
       " 17   41  695903  16973   94.1            1650  1602  West        0\n",
       " 18   41  708639  17283   93.8            1100  1340  West        0\n",
       " 19   41  684578  16697   91.9             880  1526  East        0\n",
       " 20   41  677314  16519   91.2             790  1482  West        2\n",
       " 21   41  710643  17332   90.9             780  1463  East        0\n",
       " 22   41  710557  17330   85.3             800  1338  East        0\n",
       " 23   41  654306  15958   85.2             885  1479  East        2\n",
       " 24   41  632608  15429   85.2            1800  1372  East        2\n",
       " 25   41  648952  15828   84.6             785  1502  East        2\n",
       " 26   41  697107  17002   83.8            1000  1587  East        0\n",
       " 27   41  605585  14770   77.1             890  1552  West        2\n",
       " 28   41  607203  14809   76.5             770  1463  West        2\n",
       " 29   41  655141  15979   72.4             900  1441  East        2,\n",
       " 0              Chicago Bulls\n",
       " 1           Dallas Mavericks\n",
       " 2           Sacramento Kings\n",
       " 3                 Miami Heat\n",
       " 4            Toronto Raptors\n",
       " 5       Los Angeles Clippers\n",
       " 6        Cleveland Cavaliers\n",
       " 7      Golden State Warriors\n",
       " 8      Oklahoma City Thunder\n",
       " 9            New York Knicks\n",
       " 10            Boston Celtics\n",
       " 11        Los Angeles Lakers\n",
       " 12    Portland Trail Blazers\n",
       " 13         San Antonio Spurs\n",
       " 14                 Utah Jazz\n",
       " 15             Orlando Magic\n",
       " 16      New Orleans Pelicans\n",
       " 17           Houston Rockets\n",
       " 18              Phoenix Suns\n",
       " 19            Indiana Pacers\n",
       " 20         Memphis Grizzlies\n",
       " 21         Charlotte Hornets\n",
       " 22        Philadelphia 76ers\n",
       " 23             Atlanta Hawks\n",
       " 24             Brooklyn Nets\n",
       " 25           Milwaukee Bucks\n",
       " 26        Washington Wizards\n",
       " 27            Denver Nuggets\n",
       " 28    Minnesota Timberwolves\n",
       " 29           Detroit Pistons\n",
       " Name: TEAM, dtype: object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = Data.drop(columns = 'TEAM')\n",
    "y = Data.iloc[ : , 0]\n",
    "X,y"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In above code there is drop which assists with dropping the specific segment of the data on case of above we need to drop the all out in light of the fact that we are going to predect the aggregate. In this way, with the assistance of slicing (iloc) we will take the x and y and cycle it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_y = LabelEncoder()\n",
    "y = labelencoder_y.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4,  6, 25, 15, 27, 12,  5,  9, 20, 19,  1, 13, 24, 26, 28, 21, 18,\n",
       "       10, 23, 11, 14,  3, 22,  0,  2, 16, 29,  7, 17,  8])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder_X = LabelEncoder()\n",
    "X['CONF'] = labelencoder_X.fit_transform(X['CONF'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In the above shell, labelencoder class is imported from the sklearn module preprocessing. We cannot fit the data directly into the module. We have to convert all the data in the numberic format or in the vector representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(    GMS   TOTAL    AVG    PCT  VALUE_MILLIONS   ELO  CONF  cluster\n",
       " 0    41  888882  21680  103.6            2500  1519     0        1\n",
       " 1    41  811366  19789  103.1            1450  1420     1        1\n",
       " 2    41  721928  17608  100.6            1075  1393     1        0\n",
       " 3    41  805400  19643  100.2            1350  1569     0        1\n",
       " 4    41  813050  19830  100.2            1125  1600     0        1\n",
       " 5    41  782609  19088  100.1            2000  1636     1        1\n",
       " 6    41  843042  20562  100.0            1200  1545     0        1\n",
       " 7    41  803436  19596  100.0            2600  1770     1        1\n",
       " 8    41  746323  18203  100.0            1025  1543     1        0\n",
       " 9    41  810741  19774   99.8            3300  1374     0        1\n",
       " 10   41  760690  18553   99.6            2200  1587     0        1\n",
       " 11   41  776917  18949   99.4            3000  1367     1        1\n",
       " 12   41  792029  19317   99.4            1050  1563     1        1\n",
       " 13   41  755347  18423   99.2            1175  1661     1        0\n",
       " 14   41  806605  19673   98.8             910  1617     1        1\n",
       " 15   41  727875  17753   94.2             920  1352     0        0\n",
       " 16   41  663099  16173   94.1             750  1482     1        2\n",
       " 17   41  695903  16973   94.1            1650  1602     1        0\n",
       " 18   41  708639  17283   93.8            1100  1340     1        0\n",
       " 19   41  684578  16697   91.9             880  1526     0        0\n",
       " 20   41  677314  16519   91.2             790  1482     1        2\n",
       " 21   41  710643  17332   90.9             780  1463     0        0\n",
       " 22   41  710557  17330   85.3             800  1338     0        0\n",
       " 23   41  654306  15958   85.2             885  1479     0        2\n",
       " 24   41  632608  15429   85.2            1800  1372     0        2\n",
       " 25   41  648952  15828   84.6             785  1502     0        2\n",
       " 26   41  697107  17002   83.8            1000  1587     0        0\n",
       " 27   41  605585  14770   77.1             890  1552     1        2\n",
       " 28   41  607203  14809   76.5             770  1463     1        2\n",
       " 29   41  655141  15979   72.4             900  1441     0        2,\n",
       " array([ 4,  6, 25, 15, 27, 12,  5,  9, 20, 19,  1, 13, 24, 26, 28, 21, 18,\n",
       "        10, 23, 11, 14,  3, 22,  0,  2, 16, 29,  7, 17,  8]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GMS</th>\n",
       "      <th>TOTAL</th>\n",
       "      <th>AVG</th>\n",
       "      <th>PCT</th>\n",
       "      <th>VALUE_MILLIONS</th>\n",
       "      <th>ELO</th>\n",
       "      <th>CONF</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.418981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.726379</td>\n",
       "      <td>0.726339</td>\n",
       "      <td>0.983974</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.189815</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.410675</td>\n",
       "      <td>0.410709</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.127451</td>\n",
       "      <td>0.127315</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.705320</td>\n",
       "      <td>0.705210</td>\n",
       "      <td>0.891026</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.534722</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.732323</td>\n",
       "      <td>0.732272</td>\n",
       "      <td>0.891026</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.606481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.624871</td>\n",
       "      <td>0.624891</td>\n",
       "      <td>0.887821</td>\n",
       "      <td>0.490196</td>\n",
       "      <td>0.689815</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.838191</td>\n",
       "      <td>0.838205</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.479167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.698387</td>\n",
       "      <td>0.698408</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.725490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.496786</td>\n",
       "      <td>0.496816</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.107843</td>\n",
       "      <td>0.474537</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.724173</td>\n",
       "      <td>0.724168</td>\n",
       "      <td>0.878205</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.547500</td>\n",
       "      <td>0.547467</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.568627</td>\n",
       "      <td>0.576389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.604779</td>\n",
       "      <td>0.604776</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.067130</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.658122</td>\n",
       "      <td>0.658032</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.528640</td>\n",
       "      <td>0.528654</td>\n",
       "      <td>0.858974</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.747685</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.709573</td>\n",
       "      <td>0.709551</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.062745</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.431667</td>\n",
       "      <td>0.431693</td>\n",
       "      <td>0.698718</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.032407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.203017</td>\n",
       "      <td>0.203039</td>\n",
       "      <td>0.695513</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.318810</td>\n",
       "      <td>0.318813</td>\n",
       "      <td>0.695513</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.363767</td>\n",
       "      <td>0.363676</td>\n",
       "      <td>0.685897</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.004630</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.278835</td>\n",
       "      <td>0.278871</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.435185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.253194</td>\n",
       "      <td>0.253111</td>\n",
       "      <td>0.602564</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.370840</td>\n",
       "      <td>0.370767</td>\n",
       "      <td>0.592949</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.289352</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.370537</td>\n",
       "      <td>0.370478</td>\n",
       "      <td>0.413462</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.171979</td>\n",
       "      <td>0.171925</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>0.052941</td>\n",
       "      <td>0.326389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.095388</td>\n",
       "      <td>0.095369</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.078704</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.153080</td>\n",
       "      <td>0.153111</td>\n",
       "      <td>0.391026</td>\n",
       "      <td>0.013725</td>\n",
       "      <td>0.379630</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.323060</td>\n",
       "      <td>0.323010</td>\n",
       "      <td>0.365385</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.576389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150641</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>0.495370</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005711</td>\n",
       "      <td>0.005644</td>\n",
       "      <td>0.131410</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.289352</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.174926</td>\n",
       "      <td>0.174964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.238426</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    GMS     TOTAL       AVG       PCT  VALUE_MILLIONS       ELO  CONF  cluster\n",
       "0   NaN  1.000000  1.000000  1.000000        0.686275  0.418981   0.0      0.5\n",
       "1   NaN  0.726379  0.726339  0.983974        0.274510  0.189815   1.0      0.5\n",
       "2   NaN  0.410675  0.410709  0.903846        0.127451  0.127315   1.0      0.0\n",
       "3   NaN  0.705320  0.705210  0.891026        0.235294  0.534722   0.0      0.5\n",
       "4   NaN  0.732323  0.732272  0.891026        0.147059  0.606481   0.0      0.5\n",
       "5   NaN  0.624871  0.624891  0.887821        0.490196  0.689815   1.0      0.5\n",
       "6   NaN  0.838191  0.838205  0.884615        0.176471  0.479167   0.0      0.5\n",
       "7   NaN  0.698387  0.698408  0.884615        0.725490  1.000000   1.0      0.5\n",
       "8   NaN  0.496786  0.496816  0.884615        0.107843  0.474537   1.0      0.0\n",
       "9   NaN  0.724173  0.724168  0.878205        1.000000  0.083333   0.0      0.5\n",
       "10  NaN  0.547500  0.547467  0.871795        0.568627  0.576389   0.0      0.5\n",
       "11  NaN  0.604779  0.604776  0.865385        0.882353  0.067130   1.0      0.5\n",
       "12  NaN  0.658122  0.658032  0.865385        0.117647  0.520833   1.0      0.5\n",
       "13  NaN  0.528640  0.528654  0.858974        0.166667  0.747685   1.0      0.0\n",
       "14  NaN  0.709573  0.709551  0.846154        0.062745  0.645833   1.0      0.5\n",
       "15  NaN  0.431667  0.431693  0.698718        0.066667  0.032407   0.0      0.0\n",
       "16  NaN  0.203017  0.203039  0.695513        0.000000  0.333333   1.0      1.0\n",
       "17  NaN  0.318810  0.318813  0.695513        0.352941  0.611111   1.0      0.0\n",
       "18  NaN  0.363767  0.363676  0.685897        0.137255  0.004630   1.0      0.0\n",
       "19  NaN  0.278835  0.278871  0.625000        0.050980  0.435185   0.0      0.0\n",
       "20  NaN  0.253194  0.253111  0.602564        0.015686  0.333333   1.0      1.0\n",
       "21  NaN  0.370840  0.370767  0.592949        0.011765  0.289352   0.0      0.0\n",
       "22  NaN  0.370537  0.370478  0.413462        0.019608  0.000000   0.0      0.0\n",
       "23  NaN  0.171979  0.171925  0.410256        0.052941  0.326389   0.0      1.0\n",
       "24  NaN  0.095388  0.095369  0.410256        0.411765  0.078704   0.0      1.0\n",
       "25  NaN  0.153080  0.153111  0.391026        0.013725  0.379630   0.0      1.0\n",
       "26  NaN  0.323060  0.323010  0.365385        0.098039  0.576389   0.0      0.0\n",
       "27  NaN  0.000000  0.000000  0.150641        0.054902  0.495370   1.0      1.0\n",
       "28  NaN  0.005711  0.005644  0.131410        0.007843  0.289352   1.0      1.0\n",
       "29  NaN  0.174926  0.174964  0.000000        0.058824  0.238426   0.0      1.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = (X - X.min())/(X.max()-X.min())\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The following very crutial thing in the programming is to normalize the data so the outcome that we get comes in the middle of o and 1.In the above code we are normalizing the contribution to anticipate for the results. The important preprocessing is done to get the necessary outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['GMS'] = X['GMS'].replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "There are some values that are NAN(Not A Number) in the following column of the dataset. To be precise with the calculation of any model there must be any integer value or we have to replace it by some integer, so we replace it by 0. After doing the following code we replace the value for the prediction of the model to be precise and accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GMS</th>\n",
       "      <th>TOTAL</th>\n",
       "      <th>AVG</th>\n",
       "      <th>PCT</th>\n",
       "      <th>VALUE_MILLIONS</th>\n",
       "      <th>ELO</th>\n",
       "      <th>CONF</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.418981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.726379</td>\n",
       "      <td>0.726339</td>\n",
       "      <td>0.983974</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.189815</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.410675</td>\n",
       "      <td>0.410709</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.127451</td>\n",
       "      <td>0.127315</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.705320</td>\n",
       "      <td>0.705210</td>\n",
       "      <td>0.891026</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.534722</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.732323</td>\n",
       "      <td>0.732272</td>\n",
       "      <td>0.891026</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.606481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.624871</td>\n",
       "      <td>0.624891</td>\n",
       "      <td>0.887821</td>\n",
       "      <td>0.490196</td>\n",
       "      <td>0.689815</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.838191</td>\n",
       "      <td>0.838205</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.479167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.698387</td>\n",
       "      <td>0.698408</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.725490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.496786</td>\n",
       "      <td>0.496816</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.107843</td>\n",
       "      <td>0.474537</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.724173</td>\n",
       "      <td>0.724168</td>\n",
       "      <td>0.878205</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.547500</td>\n",
       "      <td>0.547467</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.568627</td>\n",
       "      <td>0.576389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.604779</td>\n",
       "      <td>0.604776</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.067130</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.658122</td>\n",
       "      <td>0.658032</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.528640</td>\n",
       "      <td>0.528654</td>\n",
       "      <td>0.858974</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.747685</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.709573</td>\n",
       "      <td>0.709551</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.062745</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.431667</td>\n",
       "      <td>0.431693</td>\n",
       "      <td>0.698718</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.032407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.203017</td>\n",
       "      <td>0.203039</td>\n",
       "      <td>0.695513</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.318810</td>\n",
       "      <td>0.318813</td>\n",
       "      <td>0.695513</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363767</td>\n",
       "      <td>0.363676</td>\n",
       "      <td>0.685897</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.004630</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.278835</td>\n",
       "      <td>0.278871</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.435185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.253194</td>\n",
       "      <td>0.253111</td>\n",
       "      <td>0.602564</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.370840</td>\n",
       "      <td>0.370767</td>\n",
       "      <td>0.592949</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.289352</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.370537</td>\n",
       "      <td>0.370478</td>\n",
       "      <td>0.413462</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.171979</td>\n",
       "      <td>0.171925</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>0.052941</td>\n",
       "      <td>0.326389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.095388</td>\n",
       "      <td>0.095369</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.078704</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.153080</td>\n",
       "      <td>0.153111</td>\n",
       "      <td>0.391026</td>\n",
       "      <td>0.013725</td>\n",
       "      <td>0.379630</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.323060</td>\n",
       "      <td>0.323010</td>\n",
       "      <td>0.365385</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.576389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150641</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>0.495370</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005711</td>\n",
       "      <td>0.005644</td>\n",
       "      <td>0.131410</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.289352</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.174926</td>\n",
       "      <td>0.174964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.238426</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    GMS     TOTAL       AVG       PCT  VALUE_MILLIONS       ELO  CONF  cluster\n",
       "0   0.0  1.000000  1.000000  1.000000        0.686275  0.418981   0.0      0.5\n",
       "1   0.0  0.726379  0.726339  0.983974        0.274510  0.189815   1.0      0.5\n",
       "2   0.0  0.410675  0.410709  0.903846        0.127451  0.127315   1.0      0.0\n",
       "3   0.0  0.705320  0.705210  0.891026        0.235294  0.534722   0.0      0.5\n",
       "4   0.0  0.732323  0.732272  0.891026        0.147059  0.606481   0.0      0.5\n",
       "5   0.0  0.624871  0.624891  0.887821        0.490196  0.689815   1.0      0.5\n",
       "6   0.0  0.838191  0.838205  0.884615        0.176471  0.479167   0.0      0.5\n",
       "7   0.0  0.698387  0.698408  0.884615        0.725490  1.000000   1.0      0.5\n",
       "8   0.0  0.496786  0.496816  0.884615        0.107843  0.474537   1.0      0.0\n",
       "9   0.0  0.724173  0.724168  0.878205        1.000000  0.083333   0.0      0.5\n",
       "10  0.0  0.547500  0.547467  0.871795        0.568627  0.576389   0.0      0.5\n",
       "11  0.0  0.604779  0.604776  0.865385        0.882353  0.067130   1.0      0.5\n",
       "12  0.0  0.658122  0.658032  0.865385        0.117647  0.520833   1.0      0.5\n",
       "13  0.0  0.528640  0.528654  0.858974        0.166667  0.747685   1.0      0.0\n",
       "14  0.0  0.709573  0.709551  0.846154        0.062745  0.645833   1.0      0.5\n",
       "15  0.0  0.431667  0.431693  0.698718        0.066667  0.032407   0.0      0.0\n",
       "16  0.0  0.203017  0.203039  0.695513        0.000000  0.333333   1.0      1.0\n",
       "17  0.0  0.318810  0.318813  0.695513        0.352941  0.611111   1.0      0.0\n",
       "18  0.0  0.363767  0.363676  0.685897        0.137255  0.004630   1.0      0.0\n",
       "19  0.0  0.278835  0.278871  0.625000        0.050980  0.435185   0.0      0.0\n",
       "20  0.0  0.253194  0.253111  0.602564        0.015686  0.333333   1.0      1.0\n",
       "21  0.0  0.370840  0.370767  0.592949        0.011765  0.289352   0.0      0.0\n",
       "22  0.0  0.370537  0.370478  0.413462        0.019608  0.000000   0.0      0.0\n",
       "23  0.0  0.171979  0.171925  0.410256        0.052941  0.326389   0.0      1.0\n",
       "24  0.0  0.095388  0.095369  0.410256        0.411765  0.078704   0.0      1.0\n",
       "25  0.0  0.153080  0.153111  0.391026        0.013725  0.379630   0.0      1.0\n",
       "26  0.0  0.323060  0.323010  0.365385        0.098039  0.576389   0.0      0.0\n",
       "27  0.0  0.000000  0.000000  0.150641        0.054902  0.495370   1.0      1.0\n",
       "28  0.0  0.005711  0.005644  0.131410        0.007843  0.289352   1.0      1.0\n",
       "29  0.0  0.174926  0.174964  0.000000        0.058824  0.238426   0.0      1.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Initialize theta value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = [0]*len(X.columns)\n",
    "theta"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We instate theta since theta is an inclination term in multivariate Linear regression.We have the change the theta and afterward the predicted value and unique yield be in the equivalent milxa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### length of training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = len(Data)\n",
    "m"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "As there is formula so we need to ascertain the total number of lines in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### hypothethical function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypothesis(theta,X):\n",
    "    return theta*X"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We make the hypothesis function which gives the hypothetical value.\n",
    "\n",
    "H = t0+t1X1+t2X2+t3X3+....\n",
    "where, t = theta\n",
    "This gives the predected value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Compute cost\n",
    "#RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeCost(X,y,theta):\n",
    "    y1 = hypothesis(theta,X)\n",
    "    y1 = np.sum(y1, axis=1)\n",
    "    return sum(np.sqrt((y1-y)**2))/(2*m)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y1 is the predicted value\n",
    "y is the actual value\n",
    "J(t0,t1,t2,..) = 1/2m*(sum of Hi-yi)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent(X,y,theta,alpha,i):\n",
    "    J = [] #cost function in each iteration\n",
    "    k = 0\n",
    "    while k < i:\n",
    "        y1 = hypothesis(theta, X)\n",
    "        y1 = np.sum(y1, axis = 1)\n",
    "        for c in range(0, len(X.columns)):\n",
    "            theta[c] = theta[c] - alpha*(sum((y1-y)*X.iloc[:,c])/len(X))\n",
    "        j = computeCost(X,y,theta)\n",
    "        J.append(j)\n",
    "        k += 1\n",
    "    return J, j, theta"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Compute the cost and gives the value of Optimized theta \n",
    "The formula is \n",
    "T0 = T0 - alpha*(1/m)(sum of hi - yi)\n",
    "T0 = T0 - alpha*(1/m)(sum of hi - yi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### call gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "J,j,theta = gradientDescent(X,y,theta,0.5, 10000)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Here we call gradientDescent \n",
    "\n",
    "learning rate \n",
    "\n",
    "emphasess which is in just multivariate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### call hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = hypothesis(theta,X)\n",
    "y_pred = np.sum(y_pred, axis =1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "call the hypothesis and find the predicted value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.figure()\n",
    "plt.scatter(x=list(range(0,30)),y= y,color ='black')\n",
    "plt.scatter(x=list(range(0,30)),y= y_pred,color ='yellow')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "First we imported matplotlib.pyplot as plt. here in the above diagram there are two focuses they are real worth and anticipated worth. Black is indicating the real worth and yellow is demonstrating the predicte esteem which is close about each and some almost coinsides with one another that implies the model is foreseeing almost right result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.scatter(x=list(range(0,10000)),y=J)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This implies Mean Squarred Error(MSE) is less which implies theoretical worth and genuine worth contrast is likewise less in light of the fact that the expense work has diminished as demonstrated in the chart. Which expresses that the exactness of the model is precise and better."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
