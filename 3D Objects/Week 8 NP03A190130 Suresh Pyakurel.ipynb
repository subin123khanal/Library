{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PLAYER_ID</th>\n",
       "      <th>PLAYER_NAME</th>\n",
       "      <th>TEAM_ID</th>\n",
       "      <th>TEAM_ABBREVIATION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201566</td>\n",
       "      <td>Russell Westbrook</td>\n",
       "      <td>1610612760</td>\n",
       "      <td>OKC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1626246</td>\n",
       "      <td>Boban Marjanovic</td>\n",
       "      <td>1610612765</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1627743</td>\n",
       "      <td>Demetrius Jackson</td>\n",
       "      <td>1610612738</td>\n",
       "      <td>BOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>203076</td>\n",
       "      <td>Anthony Davis</td>\n",
       "      <td>1610612740</td>\n",
       "      <td>NOP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201935</td>\n",
       "      <td>James Harden</td>\n",
       "      <td>1610612745</td>\n",
       "      <td>HOU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PLAYER_ID        PLAYER_NAME     TEAM_ID TEAM_ABBREVIATION\n",
       "0     201566  Russell Westbrook  1610612760               OKC\n",
       "1    1626246   Boban Marjanovic  1610612765               DET\n",
       "2    1627743  Demetrius Jackson  1610612738               BOS\n",
       "3     203076      Anthony Davis  1610612740               NOP\n",
       "4     201935       James Harden  1610612745               HOU"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "Data = pd.read_csv('nba_2016_2017_100.csv')\n",
    "Data.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "At first we imported the necessary libraries as pandas as pd and numpy as np. The data is in the csv format which has the information of Expendeture in house hold. The expendeture of clothing, house and food is given in the above table. It is showing the table which has the total in it and head is helping to print the head few data in the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "dataset = pd.read_csv('nba_2016_2017_100.csv')\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, 3].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical data\n",
    "# Encoding the Independent Variable\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_X = LabelEncoder()\n",
    "X[:, 1] = labelencoder_X.fit_transform(X[:, 1])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In above code there is drop which helps to drop the particular column of the data in the case of above we have to drop the total because we are going to predect the total. So, with the help of slicing (iloc) we are going to take the x and y and process it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00012514864171888726, 3.290673035681129e-08,\n",
       "        0.9999999962747098],\n",
       "       [0.0010097063889781687, 3.7252902290729763e-09,\n",
       "        0.9999999993791183],\n",
       "       [0.0010106358488903224, 8.692343867836944e-09, 0.9999999826153123],\n",
       "       [0.00012608617309320397, 1.8626451145364881e-09,\n",
       "        0.9999999838570757],\n",
       "       [0.00012537774706797525, 1.6763806030828394e-08,\n",
       "        0.9999999869614842],\n",
       "       [0.00012488538787603276, 2.4214386488974348e-08,\n",
       "        0.9999999863406025],\n",
       "       [1.579523057126942e-06, 2.7318795013201828e-08, 0.999999983236194],\n",
       "       [6.277610741351841e-05, 4.967053638763969e-09, 0.9999999875823659],\n",
       "       [0.00012562051181456984, 8.071462162991448e-09,\n",
       "        0.9999999838570757],\n",
       "       [0.00012635377310799237, 1.2417634096909921e-08,\n",
       "        0.999999989445011],\n",
       "       [0.00012584961716365783, 2.2972623079283355e-08,\n",
       "        0.999999995653828],\n",
       "       [0.0001266313072300583, 1.9868214555055875e-08,\n",
       "        0.9999999931703012],\n",
       "       [0.0010096511305064373, 2.2351741374437857e-08,\n",
       "        0.9999999900658927],\n",
       "       [0.00012665924690677635, 2.980232183258381e-08,\n",
       "        0.9999999857197208],\n",
       "       [0.00012585893038923052, 1.8626451145364882e-08,\n",
       "        0.9999999844779573],\n",
       "       [0.00012563851738401036, 1.4901160916291905e-08,\n",
       "        0.9999999888241293],\n",
       "       [0.0001263475642909439, 3.228584865196579e-08, 0.9999999975164732],\n",
       "       [0.00012587631507696617, 1.55220426211374e-08, 0.9999999826153123],\n",
       "       [0.00012488662963944247, 2.9181440127738315e-08,\n",
       "        0.9999999981373549],\n",
       "       [0.00012608927750172819, 6.2088170484549606e-09,\n",
       "        0.9999999944120647],\n",
       "       [0.0001256229953413892, 1.3659397506600914e-08,\n",
       "        0.9999999975164732],\n",
       "       [0.00012538209323990917, 7.4505804581459525e-09,\n",
       "        0.9999999968955915],\n",
       "       [0.0010106476456427144, 1.9247332850210376e-08,\n",
       "        0.9999999975164732],\n",
       "       [0.0001258421665831997, 1.0554988982373434e-08,\n",
       "        0.9999999962747098],\n",
       "       [0.00012561802828775045, 2.048909625990137e-08,\n",
       "        0.9999999987582366],\n",
       "       [0.00012537650530456557, 3.1044085242274803e-09,\n",
       "        0.9999999875823659],\n",
       "       [1.3758738579376193e-06, 3.6632020585884265e-08,\n",
       "        0.9999999981373549],\n",
       "       [1.6950070542282043e-06, 9.313225572682441e-09,\n",
       "        0.9999999819944305],\n",
       "       [0.00012538023059479464, 3.414849376650228e-08,\n",
       "        0.9999999863406025],\n",
       "       [0.00012491394843445566, 2.8560558422892817e-08,\n",
       "        0.9999999981373549],\n",
       "       [0.00012516913081514716, 6.829698753300457e-09,\n",
       "        0.9999999875823659],\n",
       "       [0.00012514926260059211, 2.4835268193819842e-08,\n",
       "        0.999999983236194],\n",
       "       [0.00012465317811842055, 2.5456149898665337e-08,\n",
       "        0.9999999968955915],\n",
       "       [1.3659397506600914e-06, 3.10440852422748e-08, 0.999999995653828],\n",
       "       [0.00012585023804536266, 3.0423203537429305e-08,\n",
       "        0.9999999919285378],\n",
       "       [0.00012562858327673282, 1.1175870687218928e-08,\n",
       "        0.999999993791183],\n",
       "       [0.00012562175357797953, 1.4280279211446409e-08,\n",
       "        0.999999989445011],\n",
       "       [0.0001266611095518909, 9.934107277527937e-09, 0.999999983236194],\n",
       "       [0.00012663627428369706, 2.1730859669592362e-08,\n",
       "        0.9999999962747098],\n",
       "       [0.00012584589187342876, 2.359350478412885e-08, 1.0],\n",
       "       [0.00012609051926513787, 1.2417634096909922e-09,\n",
       "        0.9999999993791183],\n",
       "       [0.00012584340834660937, 2.1109977964746867e-08,\n",
       "        0.9999999968955915],\n",
       "       [0.00012562361622309406, 3.16649669471203e-08, 0.9999999925494195],\n",
       "       [0.00012584092481978998, 2.669791330835633e-08, 0.999999983236194],\n",
       "       [0.0001246891892573016, 1.6142924325982896e-08, 0.999999985098839],\n",
       "       [6.280218444512192e-05, 2.7939676718047323e-08,\n",
       "        0.9999999869614842],\n",
       "       [1.703699398096041e-06, 0.0, 0.9999999925494195],\n",
       "       [0.0010096747240112215, 3.6011138881038774e-08,\n",
       "        0.9999999913076562],\n",
       "       [0.00012611597541503655, 2.6077031603510835e-08,\n",
       "        0.9999999913076562],\n",
       "       [0.0001256608691253848, 1.8005569440519387e-08,\n",
       "        0.9999999906867745],\n",
       "       [0.0001253883020569576, 1.738468773567389e-08, 0.9999999925494195],\n",
       "       [1.3653188689552458e-06, 3.5390257176193276e-08,\n",
       "        0.999999993791183],\n",
       "       [0.0001266542798531376, 5.587935343609464e-09, 0.9999999869614842],\n",
       "       [0.00012517533963219562, 1.3038515801755418e-08,\n",
       "        0.9999999888241293],\n",
       "       [1.7117708602590327e-06, 2.4835268193819843e-09,\n",
       "        0.9999999993791183],\n",
       "       [0.0010107010414693311, 3.352761206165679e-08, 0.9999999931703012],\n",
       "       [0.00012516230111639387, 1.1796752392064425e-08,\n",
       "        0.9999999975164732],\n",
       "       [0.0010096840372367942, 6.208817048454961e-10, 0.999999993791183],\n",
       "       [0.00012563168768525706, 3.476937547134778e-08,\n",
       "        0.9999999906867745],\n",
       "       [0.00012494250899287856, 4.346171933918472e-09, 0.999999966472388]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Normalization               \n",
    "X = (X - X.min())/(X.max()-X.min())\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The next very crutial thing in programming is to normalize the data so that the result that we get comes in between o and 1.In the above code we are normalizing the input to predict for the outcomes. The necessary preprocessing is done to get the required result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 1, 1]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize theta value\n",
    "theta = np.matrix(np.array([1,1,1]))\n",
    "theta"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We initialize theta because theta is a bias term in multivariate Linear regression.We have the change the theta and then the predicted value and original original output be in the same milxa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#length of training set\n",
    "m = len(Data)\n",
    "m"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "As there is formula so we have to calculate the total number of rows in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hypothethical function\n",
    "def hypothesis(theta,X):\n",
    "    return theta*a"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We make the hypothesis function which gives the hypothetical value.\n",
    "h = T0+T1X1+T2X2+T3X3+....\n",
    "where, T = theta\n",
    "This gives the predected value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeCost(a, b, theta):\n",
    "    inner = np.power(((a * theta.T) - b), 2)\n",
    "    return np.sum(inner) / (2 * len(a))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "J(T0,T1,T2,..) = 1/2m*(sum of hi-yi)**2\n",
    "y1 is the predicted value\n",
    "y is the actual value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent(a, b, theta, alpha, iters):\n",
    "    temp = np.matrix(np.zeros(theta.shape))\n",
    "    parameters = int(theta.ravel().shape[1])\n",
    "    cost = np.zeros(iters)\n",
    "    \n",
    "    for i in range(iters):\n",
    "        error = (a * theta.T) - b\n",
    "        \n",
    "        for j in range(parameters):\n",
    "            term  = np.multiply(error, a[:,j])\n",
    "            temp[0,j] = theta[0,j] - ((alpha/len(a)) * np.sum(term))\n",
    "            \n",
    "        theta = temp\n",
    "        cost[i] = computeCost(X, y, theta)\n",
    "        \n",
    "    return theta, cost"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Compute the cost and gives the value of Optimized theta \n",
    "The formula is \n",
    "T0 = T0 - alpha*(1/m)(sum of hi - yi)\n",
    "T0 = T0 - alpha*(1/m)(sum of hi - yi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-08e5e48b92fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# call gradient descent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mJ\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtheta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgradientDescent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.05\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "# call gradient descent\n",
    "J,j,theta = gradientDescent(a,b,theta,0.05, 10000)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Here we call gradientDescent\n",
    "learning rate\n",
    "iterations which is in only multivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call hypothesis\n",
    "y_pred = hypothesis(theta,X)\n",
    "y_pred = np.sum(y_pred, axis =1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Here we call the hypothesis and find the predicted value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.scatter(x=list(range(0,19)),y= y,color ='red')\n",
    "plt.scatter(x=list(range(0,19)),y= y_pred,color ='green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "First we imported matplotlib.pyplot as plt. here in the above graph there are two points they are actual value and predicted value. red is showing the actual value and green is showing the predicte value which is near about each and some nearly coinsides with each other that means the model is predicting nearly right outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(x=list(range(0,10000)),y=J)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This means Mean Squarred Error(MSE) is less which means hypothetical value and actual value difference is also less because the cost function has decreased as shown in the graph. Which states that the accuracy of the model is accurate and better.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
